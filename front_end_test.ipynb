{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Dependencies\n",
    "\n",
    "1a. Clone cvat locally \n",
    "    \n",
    "    git clone https://github.com/opencv/cvat\n",
    "\n",
    "1b. Install docker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "from client.yolov7_client.yolov7_triton_client import YoloV7_Triton_Inference_Client\n",
    "from client.detectron2_client.detectron2_triton_client import Detectron2_Triton_Client\n",
    "from ipywidgets import interact, Dropdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Start Triton Inference Server and CVAT \n",
    "\n",
    "(*will likely be combined into single start up script*)\n",
    "\n",
    "2a. Triton Inference Server: run the following command, replace source with models' path\n",
    "\n",
    "    docker run --gpus all --rm --ipc=host --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 \\\n",
    "    -p8000:8000 -p8001:8001 -p8002:8002 --mount type=bind,source=\"path/to/triton/models\",destination=/models \\\n",
    "    nvcr.io/nvidia/tritonserver:22.06-py3 tritonserver --model-repository=/models --strict-model-config=false \\\n",
    "    --log-verbose 1\n",
    "\n",
    "    The command is as follows:\n",
    "    * --gpus all: specifies to use all available GPU on device\n",
    "    * --ipc=host: docker will share resource with host machine\n",
    "    * --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864: set up container runtime configs\n",
    "    * -p8000:8000: expose port 8000 for HTTP \n",
    "    * -p8001:8001: expose port 8001 for GRPC \n",
    "    * -p8002:8002: expose port 8002 for metrics \n",
    "    * -mount type=bind,source=\"path/to/triton/models\",destination=/models: mount models to container\n",
    "    * nvcr.io/nvidia/tritonserver:22.06-py3: pull from triton server image\n",
    "    * tritonserver --model-repository=/models --strict-model-config=false \\\n",
    "        --log-verbose 1: starts triton inference server\n",
    "    \n",
    "\n",
    "2b. CVAT: install local server as per instructions found [here](https://opencv.github.io/cvat/docs/administration/basics/installation/)\n",
    "\n",
    "   Once installed, to start a local CVAT server at port 8080 run the following commands\n",
    "\n",
    "    cd /path/to/cvat/clone/ \\\n",
    "    docker compose up -d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run --gpus all --rm --ipc=host --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 \\\n",
    "# -p8000:8000 -p8001:8001 -p8002:8002 --mount type=bind,source=\"path/to/triton/models\",destination=/models \\\n",
    "# nvcr.io/nvidia/tritonserver:22.06-py3 tritonserver --model-repository=/models --strict-model-config=false \\\n",
    "# --log-verbose 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: cd to baseline directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Alex Lin\\\\Desktop\\\\baseline_system'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure in baseline_system directory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Start Fiftyone Instance Locally\n",
    "\n",
    "    Run the following cell, and navigate to localhost:5151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "window.open('http://localhost:5151/');",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start fiftyone\n",
    "\n",
    "session = fo.launch_app(auto=False)\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Initilize the Model Client (and other things)\n",
    "\n",
    "\n",
    "5a. initialize the variables associated with the model as well as the class labels \n",
    "\n",
    "*Note: currently all demo models are trained on coco_classes.  If a custom model implements \\\n",
    "separate class labels, please make sure to replace the classes with the correct class label \\\n",
    "for use in annotation later*\n",
    "\n",
    "    - url: Inference server URL, default localhost:8001\n",
    "    - model_info: Print model status, configuration and statistics\n",
    "    - verbose: Enable verbose client output\n",
    "    - client_timeout: Client timeout in seconds, default no timeout\n",
    "    - ssl: Enable SSL encrypted channel to the server\n",
    "    - root_certificates: File holding PEM-encoded root certificates, default none\n",
    "    - private_key: File holding PEM-encoded private key, default is none\n",
    "    - certificate_chain: File holding PEM-encoded certicate chain default is none\n",
    "    - client_timeout: Client timeout in seconds, default no timeout\n",
    "    - width: Inference model input width, default 640\n",
    "    - height: Inference model input height, default 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_triton='localhost:8001',\n",
    "model_info=False,\n",
    "verbose=False,\n",
    "client_timeout=None,\n",
    "ssl=False,\n",
    "root_certificates=None,\n",
    "private_key=None,\n",
    "certificate_chain=None,\n",
    "width=640,\n",
    "height=640\n",
    "# change this to the class labels your model of choice was trained on.  \n",
    "# the default demo detectron2 and yolov7 labels are trained on COCO labels\n",
    "COCO_CLASSES=[\"person\",\"bicycle\",\"car\",\"motorcycle\",\"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\"fire hydrant\",\n",
    "              \"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\",\"sheep\",\"cow\",\"elephant\",\"bear\",\"zebra\",\n",
    "              \"giraffe\",\"backpack\",\"umbrella\",\"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\"kite\",\n",
    "              \"baseball bat\",\"baseball glove\",\"skateboard\",\"surfboard\",\"tennis racket\",\"bottle\",\"wine glass\",\"cup\",\"fork\",\n",
    "              \"knife\",\"spoon\",\"bowl\",\"banana\",\"apple\",\"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hot dog\",\"pizza\",\"donut\",\n",
    "              \"cake\",\"chair\",\"couch\",\"potted plant\",\"bed\",\"dining table\",\"toilet\",\"tv\",\"laptop\",\"mouse\",\"remote\",\"keyboard\",\n",
    "              \"cell phone\",\"microwave\",\"oven\",\"toaster\",\"sink\",\"refrigerator\",\"book\",\"clock\",\"vase\",\"scissors\",\"teddy bear\",\n",
    "              \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5b. select the desired client\n",
    "\n",
    "*If new clients are loaded onto the triton inference server, simply append them \\\n",
    "to the client list and add the conditionals in init_client() to create a client. \\\n",
    "Make sure to import the client*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the client\n",
    "client_list = [\"yolov7\", \"detectron2\"]\n",
    "clientW = Dropdown(options=client_list)\n",
    "client = None\n",
    "\n",
    "@interact(client_choice=clientW)\n",
    "def init_client(client_choice):\n",
    "    \"\"\"\n",
    "    Initializes client with choice from dropdown\n",
    "\n",
    "    :params:\n",
    "        - client_choice: chosen from client_list\n",
    "    \"\"\"\n",
    "    if client_choice == \"yolov7\":\n",
    "        client = YoloV7_Triton_Inference_Client(\n",
    "            url=url_triton,\n",
    "            model_info=model_info,\n",
    "            verbose=verbose,\n",
    "            client_timeout=client_timeout,\n",
    "            ssl=ssl,\n",
    "            root_certificates=root_certificates,\n",
    "            private_key=private_key,\n",
    "            certificate_chain=certificate_chain,\n",
    "            width=width,\n",
    "            height=height\n",
    "        )\n",
    "    elif client_choice == \"detectron2\":\n",
    "        client = Detectron2_Triton_Client(\n",
    "            url=url_triton,\n",
    "            model_info=model_info,\n",
    "            verbose=verbose,\n",
    "            client_timeout=client_timeout,\n",
    "            ssl=ssl,\n",
    "            root_certificates=root_certificates,\n",
    "            private_key=private_key,\n",
    "            certificate_chain=certificate_chain,\n",
    "            width=1344,\n",
    "            height=1344\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5c. Set Runtime Configs \n",
    "\n",
    "*Make sure these configs are for your desired inference mode to avoid errors*\n",
    "\n",
    "For images\n",
    "   - input_: Input directory to load from in image\n",
    "       NOTE: directory must only contain image files\n",
    "   - fo_dataset: Dataset name to export predictions to fiftyone, \n",
    "       default '', no export\n",
    "   - output_: Output directory, default no output saved\n",
    "   - tags: list of tags to organize inference results in fiftyone\n",
    "\n",
    "For videos\n",
    "   - input_: Input directory to load from in video\n",
    "       NOTE: directory must only contain video files\n",
    "   - fo_dataset: Dataset name to export predictions to fiftyone, \n",
    "       default '', no export\n",
    "   - output_: Output directory, default no output saved\n",
    "   - fps: Video output fps, default 24.0 FPS\n",
    "   - tags: list of tags to organize inference results in fiftyone\n",
    "\n",
    "Dummy requires no input \n",
    "\n",
    "\n",
    "*Operations to export to fiftyone and export locally can both be down.  Visualization \\\n",
    "(not listed here) is limited and should only be used for development*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = ''\n",
    "output_ = ''\n",
    "fo_dataset = ''\n",
    "fps = 24.0\n",
    "tags = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5d. Run Inference in Desired Mode\n",
    "\n",
    "**If exported to fiftyone, navigate to your fiftyone client (should be a webpage \\\n",
    "at localhost:5151), refresh, and select the dataset exported to to see inference \\\n",
    "results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_choice = ['image', 'video', 'dummy']\n",
    "inferenceW = Dropdown(options=inference_choice)\n",
    "\n",
    "@interact(mode=inferenceW)\n",
    "def inference(mode):\n",
    "    \"\"\"\n",
    "    Runs inference through Triton Inference Server \n",
    "\n",
    "    :params:\n",
    "        - mode, media type to run through server, chosen from inference_choice\n",
    "    \"\"\"\n",
    "    if mode == 'image':\n",
    "        client.infer_image(input_=input_, output_=output_, fo_dataset=fo_dataset, tags=tags)\n",
    "    elif mode == 'video':\n",
    "        client.infer_video(input_=input_, output_=output_, fo_dataset=fo_dataset, fps=fps, tags=tags)\n",
    "    elif mode == 'dummy':\n",
    "        client.infer_dummy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Validation Via CVAT\n",
    "\n",
    "Once inference has completed, validation may be performed through CVAT.  The dataset \n",
    "visualized in fiftyone would then be uploaded to CVAT, ground truth can be annotated,\n",
    "and the result imported back to fiftyone for analysis.\n",
    "\n",
    "6a. Load the desired dataset (of all available on fiftyone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = fo.list_datasets()\n",
    "datasetsW = Dropdown(options=datasets)\n",
    "dataset = None\n",
    "\n",
    "@interact(dataset_choice=datasetsW)\n",
    "def init_dataset(dataset_choice):\n",
    "    # load dataset \n",
    "    dataset = fo.load_dataset(dataset_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**WARNING: The follow will delete the selected samples from a dataset in fiftyone, \\\n",
    "only run if you are for sure deleting them as they cannot be recovered**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete selected samples\n",
    "delete_view = dataset.select(session.selected)\n",
    "dataset.delete_samples(delete_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6b. Config for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_key = \"test_run_images\"\n",
    "label_field=\"ground_truth\"\n",
    "label_type='detections'\n",
    "classes=COCO_CLASSES\n",
    "launch_editor=True\n",
    "url_cvat=\"http://localhost:8080\"\n",
    "username=\"django\"\n",
    "password=\"bfc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6c. Run CVAT Validation\n",
    "\n",
    "Specific Metrics to Pick Data to Validate, **come up with them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create specific view for low confidence model predictions\n",
    "low_conf_view = (\n",
    "    dataset\n",
    "    .filter_labels(\"model_detections\", F(\"confidence\") < 0.6)\n",
    "    .sort_by(F(\"model_detections.confidence\"), reverse=True)\n",
    ")\n",
    "\n",
    "sample_id = low_conf_view.head(3)\n",
    "view = dataset.select(sample_id)\n",
    "\n",
    "# send samples to CVAT\n",
    "view.annotate(\n",
    "    anno_key,\n",
    "    label_field=label_field,\n",
    "    label_type=label_type,\n",
    "    classes=classes,\n",
    "    launch_editor=launch_editor,\n",
    "    url=url_cvat,\n",
    "    username=username,\n",
    "    password=password,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6d. Merge Dataset Back to Fiftyone and Cleanup CVAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge annotations back to Fiftyone dataset\n",
    "dataset.load_annotations(anno_key)\n",
    "dataset.load_annotation_view(anno_key)\n",
    "\n",
    "# Delete tasks from CVAT\n",
    "results = dataset.load_annotation_results(anno_key)\n",
    "results.cleanup()\n",
    "\n",
    "# Delete run record (not the labels) from FiftyOne\n",
    "dataset.delete_annotation_run(anno_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
