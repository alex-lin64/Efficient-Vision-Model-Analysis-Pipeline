{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Dependencies\n",
    "\n",
    "*Make sure to follow the installation first in the readme*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from client.yolov7_client.yolov7_triton_client import YoloV7_Triton_Inference_Client\n",
    "from client.detectron2_client.detectron2_triton_client import Detectron2_Triton_Client\n",
    "from client.utils.exports import export_image_to_fo, export_video_to_fo\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "import json\n",
    "import imghdr\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Start Triton Inference Server and CVAT \n",
    "\n",
    "(*will likely be combined into single start up script*)\n",
    "\n",
    "2a. Triton Inference Server: run the following command, replace source with models' path\n",
    "\n",
    "    docker run --gpus all --rm --ipc=host --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 \\\n",
    "    -p8000:8000 -p8001:8001 -p8002:8002 --mount type=bind,source=\"path/to/triton/models\",destination=/models \\\n",
    "    nvcr.io/nvidia/tritonserver:22.06-py3 tritonserver --model-repository=/models --strict-model-config=false \\\n",
    "    --log-verbose 1\n",
    "\n",
    "        The command is as follows:\n",
    "        * --gpus all: specifies to use all available GPU on device\n",
    "        * --ipc=host: docker will share resource with host machine\n",
    "        * --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864: set up container runtime configs\n",
    "        * -p8000:8000: expose port 8000 for HTTP \n",
    "        * -p8001:8001: expose port 8001 for GRPC \n",
    "        * -p8002:8002: expose port 8002 for metrics \n",
    "        * -mount type=bind,source=\"path/to/triton/models\",destination=/models: mount models to container\n",
    "        * nvcr.io/nvidia/tritonserver:22.06-py3: pull from triton server image\n",
    "        * tritonserver --model-repository=/models --strict-model-config=false \\\n",
    "            --log-verbose 1: starts triton inference server\n",
    "    \n",
    "\n",
    "2b. CVAT: install local server as per instructions found [here](https://opencv.github.io/cvat/docs/administration/basics/installation/)\n",
    "\n",
    "   Once installed, to start a local CVAT server at port 8080 run the following commands\n",
    "\n",
    "    cd /path/to/cvat/clone/ \\\n",
    "    CVAT_VERSION=v2.3.0 docker compose up -d  \n",
    "\n",
    "*note: cvat only works with fiftyone's api up to cvat v2.3.0*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Start Fiftyone Instance Locally\n",
    "\n",
    "Run the following cell, and navigate to localhost:5151\n",
    "\n",
    "*If the error \"Could not connect session, trying again in 10 seconds\" occurs, \n",
    "it is likely the session is already started.  In that case nagivate to \n",
    "localhost:5151 and see if a session is already started*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "window.open('http://localhost:5151/');",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start fiftyone\n",
    "\n",
    "session = fo.launch_app(auto=False)\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) 3a. Upload labeled dataset (if wish to evaluate model performance)\n",
    "\n",
    "Demo: Upload COCO validation dataset to Fiftyone with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\Alex Lin\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'C:\\Users\\Alex Lin\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Found 100 (< 5000) downloaded images; must download full image zip\n",
      "Downloading images to 'C:\\Users\\Alex Lin\\fiftyone\\coco-2017\\tmp-download\\val2017.zip'\n",
      " 100% |██████|    6.1Gb/6.1Gb [1.4m elapsed, 0s remaining, 86.4Mb/s]      \n",
      "Extracting images to 'C:\\Users\\Alex Lin\\fiftyone\\coco-2017\\validation\\data'\n",
      "Writing annotations to 'C:\\Users\\Alex Lin\\fiftyone\\coco-2017\\validation\\labels.json'\n",
      "Dataset info written to 'C:\\Users\\Alex Lin\\fiftyone\\coco-2017\\info.json'\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [29.7s elapsed, 0s remaining, 163.4 samples/s]      \n",
      "Dataset 'baseline_demo' created\n"
     ]
    }
   ],
   "source": [
    "dataset_demo = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    dataset_name=\"baseline_demo\"\n",
    ")\n",
    "dataset_demo.persistent = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) 3b. Alternatively, any desired dataset with labels can be uploaded to Fiftyone below \n",
    "from a annotations.json file with the format by providing the file \n",
    "\n",
    "    Images\n",
    "        {\n",
    "            \"path/to/image\": {\n",
    "                \"detections\": [\n",
    "                    {\n",
    "                        \"bbox\": [<top-left-x>, <top-left-y>, <width>, <height>],\n",
    "                        \"label\": obj_class,\n",
    "                        \"confidence\": 0.00-1.00\n",
    "                    }\n",
    "                ],\n",
    "                \"tags\": [training/validation/testing]\n",
    "            }\n",
    "            ...\n",
    "        }\n",
    "\n",
    "                            OR\n",
    "\n",
    "    Videos\n",
    "        {\n",
    "            \"path/to/video\": {\n",
    "                1: {\n",
    "                    \"detections\": [\n",
    "                        {\n",
    "                            \"bbox\": [<top-left-x>, <top-left-y>, <width>, <height>],\n",
    "                            \"label\": obj_class,\n",
    "                            \"confidence\": 0.00-1.00\n",
    "                        }\n",
    "                    ],\n",
    "                    tags\": [training/validation/testing],\n",
    "                }\n",
    "                2: { ... }\n",
    "            }\n",
    "            ...\n",
    "        }\n",
    "\n",
    "*note: vscode jupyter does not support fileupload widget, so uploads will be specified \\\n",
    "by the file path to the json file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting image annotations...\n",
      "Dataset does not exist in fiftyone, creating new                 dataset by default.  Make sure the dataset set to persistent                 if using existing fiftyone datset\n",
      " 100% |█████████████████████| 4/4 [97.7ms elapsed, 0s remaining, 40.9 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# path of file to be uploaded to fiftyone as labeled dataset\n",
    "json_file = \"C:\\\\Users\\\\Alex Lin\\\\Desktop\\\\baseline_system\\\\data\\\\inference\\\\images\\\\test1.json\"\n",
    "# name of the new dataset\n",
    "dataset_name = 'inference_test'\n",
    "# name of label of detections in fiftyone\n",
    "label_field = 'ground_truth'   \n",
    "\n",
    "\n",
    "with open(json_file) as json_file:\n",
    "    try:\n",
    "        # laod .json file\n",
    "        annotations = json.load(json_file)\n",
    "        # check for empty file\n",
    "        if not annotations:\n",
    "            print(\"Error: .json file is empty\")\n",
    "            sys.exit(1)\n",
    "        # check if image or video annotations\n",
    "        if imghdr.what(list(annotations.keys())[0]):\n",
    "            print(\"Exporting image annotations...\")\n",
    "            export_image_to_fo(annotations=annotations, dataset=dataset_name, label_field=label_field)\n",
    "        else:\n",
    "            print(\"Exporting video annotations...\")\n",
    "            export_video_to_fo(annotations=annotations, dataset=dataset_name, label_field=label_field)\n",
    "    except ValueError as e:\n",
    "        print(\"Invalid .json file\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Initilize the Model Client, Run Inference\n",
    "\n",
    "\n",
    "4a. initialize the variables associated with the model as well as the class labels \n",
    "\n",
    "*Note: currently all demo models are trained on coco_classes.  If a custom model implements \\\n",
    "separate class labels, please make sure to replace the classes with the correct class label \\\n",
    "for use in annotation later*\n",
    "\n",
    "    - url: Inference server URL, default localhost:8001\n",
    "    - model_info: Print model status, configuration and statistics\n",
    "    - verbose: Enable verbose client output\n",
    "    - client_timeout: Client timeout in seconds, default no timeout\n",
    "    - ssl: Enable SSL encrypted channel to the server\n",
    "    - root_certificates: File holding PEM-encoded root certificates, default none\n",
    "    - private_key: File holding PEM-encoded private key, default is none\n",
    "    - certificate_chain: File holding PEM-encoded certicate chain default is none\n",
    "    - client_timeout: Client timeout in seconds, default no timeout\n",
    "    - width: Inference model input width, default 640\n",
    "    - height: Inference model input height, default 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_triton='localhost:8001'\n",
    "model_info=False\n",
    "verbose=False\n",
    "client_timeout=None\n",
    "ssl=False\n",
    "root_certificates=None\n",
    "private_key=None\n",
    "certificate_chain=None\n",
    "width=640\n",
    "height=640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4b. select the desired client\n",
    "\n",
    "*If new clients are loaded onto the triton inference server, simply append them \\\n",
    "to the client list and add the conditionals in init_client() to create a client. \\\n",
    "Make sure to import the client*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffc87f2a63b4fc081361eb76b631d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='client_choice', options=('select', 'yolov7', 'detectron2'), value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the client\n",
    "client_list = [\"select\", \"yolov7\", \"detectron2\"]\n",
    "clientW = Dropdown(options=client_list)\n",
    "client = [None]\n",
    "\n",
    "@interact(client_choice=clientW)\n",
    "def init_client(client_choice):\n",
    "    \"\"\"\n",
    "    Initializes client with choice from dropdown\n",
    "\n",
    "    :params:\n",
    "        - client_choice: chosen from client_list\n",
    "    \"\"\"\n",
    "    if client_choice == \"select\":\n",
    "        return\n",
    "    elif client_choice == \"yolov7\":\n",
    "        client[0] = (YoloV7_Triton_Inference_Client(\n",
    "            url=url_triton,\n",
    "            model_info=model_info,\n",
    "            verbose=verbose,\n",
    "            client_timeout=client_timeout,\n",
    "            ssl=ssl,\n",
    "            root_certificates=root_certificates,\n",
    "            private_key=private_key,\n",
    "            certificate_chain=certificate_chain,\n",
    "            width=width,\n",
    "            height=height\n",
    "        ))\n",
    "    elif client_choice == \"detectron2\":\n",
    "        client[0] = (Detectron2_Triton_Client(\n",
    "            url=url_triton,\n",
    "            model_info=model_info,\n",
    "            verbose=verbose,\n",
    "            client_timeout=client_timeout,\n",
    "            ssl=ssl,\n",
    "            root_certificates=root_certificates,\n",
    "            private_key=private_key,\n",
    "            certificate_chain=certificate_chain,\n",
    "            width=1344,\n",
    "            height=1344\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) 4c. Select the existing dataset on fiftyone to use\n",
    "\n",
    "This would ideally be a labelled dataset to have the model make predictions on,\n",
    "which would then be imported back to fiftyone/cvat for validation and to calculate\n",
    "analysis metrics on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04dc32e9a8d4bb482085f626febe97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset_choice', options=('select', 'inference_test', 'inference_t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = [\"select\"] + fo.list_datasets()\n",
    "datasetsW = Dropdown(options=datasets)\n",
    "# create a global var, since dataset object don't seem permanent across cells\n",
    "dataset = [None]\n",
    "\n",
    "@interact(dataset_choice=datasetsW)\n",
    "def init_dataset(dataset_choice):\n",
    "    if dataset_choice == \"select\":\n",
    "        return\n",
    "    # load dataset \n",
    "    dataset[0] = (fo.load_dataset(dataset_choice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4d. Set Runtime Configs \n",
    "\n",
    "*Make sure these configs are for your desired inference mode to avoid errors*\n",
    "\n",
    "For images \n",
    "   - input_: Input directory to load from in image \n",
    "       NOTE: directory must only contain image files\n",
    "   - vis: Show visualization of prediction on computer, default false\n",
    "   - output_: Output directory, default no output saved\n",
    "   - fo_dataset: fiftyone dataset of labeled images to validate/test model with\n",
    "       default None, no dataset used\n",
    "   - create_fo_ds: name of new fiftyone dataset to create, **ONLY** used in combination \\\n",
    "       with input_ (inferencing locally, want to visualize results only)\n",
    "   - json_out: Output directory for annotations outputs, includes filename\n",
    "       e.g. /my/output/file/path/myfile.json\n",
    "   - tags: list of tags to organize inference results in fiftyone\n",
    "\n",
    "For videos\n",
    "   - input_: Input directory to load from in video OR a fiftyone dataset \\\n",
    "       of labeled images to validate/test model with \n",
    "       NOTE: directory must only contain video files\n",
    "   - vis: Show visualization of prediction on computer, default false\n",
    "   - fo_dataset: Dataset name to export predictions to fiftyone, \n",
    "       default '', no export\n",
    "   - create_fo_ds: name of new fiftyone dataset to create, **ONLY** used in combination \\\n",
    "       with input_ (inferencing locally, want to visualize results only)\n",
    "   - json_out: Output directory for annotations outputs, includes filename\n",
    "       e.g. /my/output/file/path/myfile.json            \n",
    "   - output_: Output directory, default no output saved\n",
    "   - fps: Video output fps, default 24.0 FPS\n",
    "   - tags: list of tags to organize inference results in fiftyone\n",
    "\n",
    "Dummy requires no input \n",
    "\n",
    "**Can either have input form local directory or from fiftyone, not both**\n",
    "\n",
    "*Operations to export to fiftyone and export locally can both be down.  Local \\\n",
    "visualization options (not listed here) is limited and should only be used for \\\n",
    "development*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to dataset[0]\n",
    "fo_dataset = dataset[0]\n",
    "\n",
    "# OR\n",
    "\n",
    "# set these fields manually\n",
    "input_ = ''\n",
    "output_ = ''\n",
    "create_fo_ds = ''\n",
    "json_out = ''\n",
    "fps = 24.0\n",
    "\n",
    "# tags to be added\n",
    "tags = [\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4e. Run Inference in Desired Mode\n",
    "\n",
    "**If exported to fiftyone, navigate to your fiftyone client (should be a webpage \\\n",
    "at localhost:5151), refresh, and select the dataset exported to to see inference \\\n",
    "results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1b23719c344218a5bd0d09f5fef235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='mode', options=('select', 'image', 'video', 'dummy'), value='selec…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference_choice = ['select', 'image', 'video', 'dummy']\n",
    "inferenceW = Dropdown(options=inference_choice)\n",
    "\n",
    "@interact(mode=inferenceW)\n",
    "def inference(mode):\n",
    "    \"\"\"\n",
    "    Runs inference through Triton Inference Server \n",
    "\n",
    "    :params:\n",
    "        - mode, media type to run through server, chosen from inference_choice\n",
    "    \"\"\"\n",
    "    if mode == 'select':\n",
    "        return\n",
    "    elif mode == 'image':\n",
    "        client[0].infer_image(\n",
    "            input_=input_, \n",
    "            output_=output_, \n",
    "            fo_dataset=fo_dataset, \n",
    "            create_fo_ds=create_fo_ds,\n",
    "            json_out=json_out, \n",
    "            tags=tags\n",
    "            )\n",
    "    elif mode == 'video':\n",
    "        client[0].infer_video(\n",
    "            input_=input_, \n",
    "            output_=output_, \n",
    "            fo_dataset=fo_dataset, \n",
    "            create_fo_ds=create_fo_ds,\n",
    "            fps=fps, \n",
    "            json_out=json_out, \n",
    "            tags=tags\n",
    "            )\n",
    "    elif mode == 'dummy':\n",
    "        client[0].infer_dummy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Validation Via CVAT\n",
    "\n",
    "Once inference has completed, validation may be performed through CVAT.  The dataset \n",
    "visualized in fiftyone would then be uploaded to CVAT, ground truth can be annotated,\n",
    "and the result imported back to fiftyone for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5a. Config for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\"n/a\", \"red\", \"blue\", \"green\", \"yellow\", \"purple\", \"pink\", \"orange\", \"brown\", \"black\", \"white\", \"gray\", \n",
    "          \"gold\", \"silver\", \"navy blue\", \"sky blue\", \"lime green\", \"teal\", \"indigo\", \"magenta\", \"violet\", \n",
    "          \"khaki\", \"salmon\", \"crimson\", \"lavender\", \"plum\", \"blue violet\", \"olive\", \"cyan\", \"maroon\", \"beige\"]\n",
    "\n",
    "# change this to the class labels your model of choice was trained on.  \n",
    "# the default demo detectron2 and yolov7 labels are trained on COCO labels\n",
    "COCO_CLASSES=[\"person\",\"bicycle\",\"car\",\"motorcycle\",\"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\"fire hydrant\", \n",
    "              \"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\",\"sheep\",\"cow\",\"elephant\",\"bear\",\"zebra\",\n",
    "              \"giraffe\",\"backpack\",\"umbrella\",\"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\"kite\",\n",
    "              \"baseball bat\",\"baseball glove\",\"skateboard\",\"surfboard\",\"tennis racket\",\"bottle\",\"wine glass\",\"cup\",\"fork\",\n",
    "              \"knife\",\"spoon\",\"bowl\",\"banana\",\"apple\",\"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hot dog\",\"pizza\",\"donut\",\n",
    "              \"cake\",\"chair\",\"couch\",\"potted plant\",\"bed\",\"dining table\",\"toilet\",\"tv\",\"laptop\",\"mouse\",\"remote\",\"keyboard\",\n",
    "              \"cell phone\",\"microwave\",\"oven\",\"toaster\",\"sink\",\"refrigerator\",\"book\",\"clock\",\"vase\",\"scissors\",\"teddy bear\",\n",
    "              \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "label_schema = {\n",
    "    \"novel_detections\": {\n",
    "        \"type\": \"detections\",\n",
    "        \"classes\": [\"novel_object\"],\n",
    "        \"attributes\": {\n",
    "            \"novelty\": {\n",
    "                \"type\": \"select\",\n",
    "                \"values\": [\"not seen before\", \"new presentation\", \"idfk\"],\n",
    "                \"default\": \"not seen before\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"model_detections\": {},\n",
    "}\n",
    "\n",
    "anno_key = \"test_run_images36\"\n",
    "launch_editor=False\n",
    "url_cvat=\"http://localhost:8080\"\n",
    "username=\"django\"\n",
    "password=\"bfc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5b. Run CVAT Validation\n",
    "\n",
    "Specific Metrics to Pick Data to Validate, **come up with them**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing field 'model_detections' with multiple types ['detections', 'instances']. Only the 'detections' will be annotated\n",
      "Uploading samples to CVAT...\n",
      "Launching editor at 'http://localhost:8080/tasks/3/jobs/3'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fiftyone.utils.cvat.CVATAnnotationResults at 0x19a54fceee0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create specific view for low confidence model predictions\n",
    "low_conf_view = (\n",
    "    dataset[0] \\\n",
    "    .filter_labels(\"model_detections\", F(\"confidence\") < 0.6)\n",
    "    .sort_by(F(\"predictions.detections\").length(), reverse=True)\n",
    "    ) \\\n",
    "\n",
    "# fastdup, cleanlab\n",
    "\n",
    "sample_id = low_conf_view.head(3)\n",
    "view = dataset[0].select(sample_id)\n",
    "\n",
    "anno_keys = dataset[0].list_annotation_runs()\n",
    "\n",
    "# check if anno key already exists\n",
    "if anno_key in anno_keys:\n",
    "    # Delete tasks from CVAT\n",
    "    results = dataset[0].load_annotation_results(anno_key)\n",
    "    if results is not None:\n",
    "        results.cleanup()\n",
    "    dataset[0].delete_annotation_run(anno_key)\n",
    "\n",
    "# send samples to CVAT\n",
    "view.annotate(\n",
    "    anno_key,\n",
    "    label_schema=label_schema,\n",
    "    launch_editor=True,\n",
    "    allow_additions=True,\n",
    "    allow_deletions=False,\n",
    "    allow_label_edits=True,\n",
    "    allow_index_edits=True,\n",
    "    allow_spatial_edits=True,\n",
    "    url=\"http://localhost:8080\",\n",
    "    username=\"django\",\n",
    "    password=\"arclight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5c. Merge Dataset Back to Fiftyone and Cleanup CVAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading labels from CVAT...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete\n",
      "Loading labels for field 'novel_detections'...\n",
      " 100% |█████████████████████| 1/1 [54.6ms elapsed, 0s remaining, 18.3 samples/s] \n",
      "Loading labels for field 'model_detections'...\n",
      "                                                                              100% |█████████████████████| 2/2 [54.7ms elapsed, 0s remaining, 36.6 samples/s] \n",
      "Deleting tasks...\n",
      " 100% |█████████████████████| 1/1 [320.4ms elapsed, 0s remaining, 3.1 samples/s] \n"
     ]
    }
   ],
   "source": [
    "# merge annotations back to Fiftyone dataset\n",
    "dataset[0].load_annotations(anno_key)\n",
    "dataset[0].load_annotation_view(anno_key)\n",
    "\n",
    "# Delete tasks from CVAT\n",
    "results = dataset[0].load_annotation_results(anno_key)\n",
    "results.cleanup()\n",
    "\n",
    "# Delete run record (not the labels) from FiftyOne\n",
    "dataset[0].delete_annotation_run(anno_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Analysis and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Step 7. Cleanup\n",
    "\n",
    "Make sure to select the proper dataset by running the cell in step 5c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING: The follow will delete the selected samples from a dataset in fiftyone, \\\n",
    "only run if the selected samples in the dataset is to be deleted as they cannot \\\n",
    "be recovered**\n",
    "\n",
    "*if error 'name 'session' is not defined' is thrown, restart kernel and rerun \\\n",
    "everything*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete selected samples\n",
    "delete_view = dataset[0].select(session.selected)\n",
    "dataset[0].delete_samples(delete_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING: The follow will delete the selected dataset from fiftyone, \\\n",
    "only run if the selected dataset in the dataset is to be deleted as they cannot \\\n",
    "be recovered**\n",
    "\n",
    "*Fiftyone might have to be restarted (close tab and rerun step 4) if the \\\n",
    "deleted dataset is currently being viewed in the webapp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
